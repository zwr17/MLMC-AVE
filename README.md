# Multi-Event-Localization-by-Audio-Visual-Fusion-with-Omnidirectional-Camera-and-Microphone-Array

This program is for the audio-visual recognition task for more real life in a school or an office. The dataset is made up of omnidirectional video and corresponding 8-channel audio. We film the omnidirectional video by theta-v and 8-channel audio by the Tamago device.
![image](https://github.com/zwr17/Multi-Event-Localization-by-Audio-Visual-Fusion-with-Omnidirectional-Camera-and-Microphone-Array/blob/main/device_dataset.png)

## Details
We defined 12 event categories assuming an indoor office environment with multiple sound sources. The defined categories are
man speaking, woman speaking, walking, typing, kettle boiling, writing on board, alarming, opening the door, opening the drawer, coughing, printer working,and cleaner working. There is also a category nothing for scenes without any event; thus, the total number of categories in our dataset is 13. 660 videos were collected, and the distribution of each category is shown in the following image. 
![image](https://github.com/zwr17/Multi-Event-Localization-by-Audio-Visual-Fusion-with-Omnidirectional-Camera-and-Microphone-Array/blob/main/category_distri.png)
<div align=center><img width="800" src="https://github.com/zwr17/Multi-Event-Localization-by-Audio-Visual-Fusion-with-Omnidirectional-Camera-and-Microphone-Array/blob/main/category_distri.png"/></div>

And each video contains at least one AVE. Some examples of our dataset are shown here.
![image](https://github.com/zwr17/Multi-Event-Localization-by-Audio-Visual-Fusion-with-Omnidirectional-Camera-and-Microphone-Array/blob/main/example.png)

## Notice
We want to inform you that this dataset contains a person's face, so if you want to use or edit it, it is better to notify us of your aim.

